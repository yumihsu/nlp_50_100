{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 熟練自定義collate_fn與sampler進行資料讀取\n",
    "\n",
    "本此作業主要會使用[IMDB](http://ai.stanford.edu/~amaas/data/sentiment/)資料集利用Pytorch的Dataset與DataLoader進行\n",
    "客製化資料讀取。\n",
    "下載後的資料有分成train與test，因為這份作業目的在讀取資料，所以我們取用train部分來進行練習。\n",
    "(請同學先行至IMDB下載資料)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/xuyouming/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/xuyouming/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import torch and other required modules\n",
    "import glob\n",
    "import torch\n",
    "import re\n",
    "import os \n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "nltk.download('stopwords') #下載stopwords\n",
    "nltk.download('punkt') #下載word_tokenize需要的corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 探索資料與資料前處理\n",
    "這份作業我們使用test資料中的pos與neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab length before removing stopwords: 89527\n",
      "vocab length after removing stopwords: 89356\n"
     ]
    }
   ],
   "source": [
    "# 讀取字典，這份字典為review內所有出現的字詞\n",
    "###<your code>###\n",
    "with open(os.path.join('E:\\\\jupyter\\\\dataset\\\\aclimdb\\\\','imdb.vocab'), encoding = 'utf-8') as e:\n",
    "    vocab = [word.strip() for word in e.read().split('\\n')]\n",
    "\n",
    "# # 以nltk stopwords移除贅字，過多的贅字無法提供有用的訊息，也可能影響模型的訓練\n",
    "print(f\"vocab length before removing stopwords: {len(vocab)}\")\n",
    "vocab = [i for i in vocab if i not in stopwords.words('english')]\n",
    "print(f\"vocab length after removing stopwords: {len(vocab)}\")\n",
    "# # 將字典轉換成dictionary\n",
    "vocab = dict( [i[1],i[0]]for i in enumerate(vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('E:\\\\jupyter\\\\dataset\\\\aclimdb\\\\train\\\\pos\\\\0_9.txt', 0), ('E:\\\\jupyter\\\\dataset\\\\aclimdb\\\\train\\\\pos\\\\10000_8.txt', 0)]\n",
      "Total reviews: 25000\n"
     ]
    }
   ],
   "source": [
    "# 將資料打包成(x, y)配對，其中x為review的檔案路徑，y為正評(1)或負評(0)\n",
    "# 這裡將x以檔案路徑代表的原因是讓同學練習不一次將資料全讀取進來，若電腦記憶體夠大(所有資料檔案沒有很大)\n",
    "# 可以將資料全一次讀取，可以減少在訓練時I/O時間，增加訓練速度\n",
    "path = os.path.join('E:\\\\jupyter\\\\dataset\\\\aclimdb\\\\train\\\\')\n",
    "pos_dir_list = [(path + 'pos\\\\' + i , 0) for i in os.listdir(path + '/pos')]\n",
    "neg_dir_list = [(path + 'neg\\\\' + i , 1) for i in os.listdir(path + '/neg')]\n",
    "review_pairs = pos_dir_list + neg_dir_list\n",
    "\n",
    "print(review_pairs[:2])\n",
    "print(f\"Total reviews: {len(review_pairs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 建立Dataset, DataLoader, Sampler與Collate_fn讀取資料\n",
    "這裡我們會需要兩個helper functions，其中一個是讀取資料與清洗資料的函式(load_review)，另外一個是生成詞向量函式\n",
    "(generate_vec)，注意這裡我們用來產生詞向量的方法是單純將文字tokenize(為了使產生的文本長度不同，而不使用BoW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_review(review_path):\n",
    "    with open(review_path, encoding = 'utf-8') as e:\n",
    "        review = e.read()\n",
    "    review = re.sub(r'\\W', ' ', review)\n",
    "    review = nltk.word_tokenize(review)\n",
    "    return review\n",
    "\n",
    "def generate_vec(review, vocab_dic):\n",
    "    vec = [vocab_dic[word] for word in review if vocab_dic.get(word)]\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#建立客製化dataset\n",
    "class dataset(Dataset):\n",
    "    '''custom dataset to load reviews and labels\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_pairs: list\n",
    "        directory of all review-label pairs\n",
    "    vocab: list\n",
    "        list of vocabularies\n",
    "    '''\n",
    "    def __init__(self, data_pairs ,vocab):\n",
    "        self.data_pairs = data_pairs\n",
    "        self.vocab = vocab\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_pairs) \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_path ,y = self.data_pairs[idx]\n",
    "        x_word = load_review(x_path)\n",
    "        x_vec = generate_vec(x_word, self.vocab)\n",
    "        return x_vec, y        \n",
    "\n",
    "#建立客製化collate_fn，將長度不一的文本pad 0 變成相同長度\n",
    "def collate_fn(batch):\n",
    "    reviews, labels = zip(*batch)\n",
    "    lengths = torch.LongTensor([len(i) for i in reviews])\n",
    "    labels = torch.LongTensor(labels)\n",
    "    reviews = pad_sequence([\n",
    "        torch.LongTensor(review) for review in reviews\n",
    "    ], batch_first=True, padding_value=0)\n",
    "    return reviews, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1241,   128,    10, 20044, 17112,  3705,   595, 16901,  3533,  4141,\n",
       "           6090,   362,    61,   789,  8187,   159,   378,    18,   322,   281,\n",
       "             25,    93,  1568, 11665,   159,  3189,  1007,    79,   211,  8754,\n",
       "          75154, 75154,    17,  2428,  3856,   272,   160,    31,    31,   180,\n",
       "           1808,  1557,    20,    49,    49,    28,  1518, 27011,   394,  3323,\n",
       "          75154, 75154,    46,    26,   437,    61,    21,   101,   930,  1350,\n",
       "          27377, 27377,    20,   125,    49,    22,  2218,  8731,   916,  1346,\n",
       "           3522,   472,    45,  2524,  1894,  3448,  5182,    12,   497,    28,\n",
       "          16284,  1856,  1094,    53,   224,   104,   981,  8837,    31, 75154,\n",
       "          75154,   240,   112,    98,    28,    24,  6255,  3239,   261,   128,\n",
       "            114, 15540,  1177,  1403,  8383,   512,   136,   102,    24,  2283,\n",
       "            491,   443,   263,  3187,   747,    86,    14,  1810,   215,    79,\n",
       "           8844,   128, 75154, 75154,   699,   602,  2382,    49, 48525,    11,\n",
       "             79,  5971,   121,  1115,   482,  8249,   119,   899,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0],\n",
       "         [  566, 75154, 75154,  6067,  4483,  2797,   106,   304,   211, 33039,\n",
       "            214,   529,   616,  1010,   177, 15328,   363,   768,  1681,   245,\n",
       "           1156,   174,   197,  6213,   383,  7693,  5946,     1, 50262, 18019,\n",
       "           5071,    32,  3560,  7044,   168,   106,  2087,    23,  8494,   940,\n",
       "           1304,  3859,  1184, 75154, 75154,     1,   266,    83,  9398,   626,\n",
       "           1817,   822,  1449,   103,   899,  3076,  1681,   819,  1471,    40,\n",
       "           5688,   756,   427,  4899, 11855,   390,  2826,   361,   586,   451,\n",
       "           2576,  4882,   427,  3850,  4322,  5501,  1681, 20178,  2024,  1226,\n",
       "            208,    23,   566,   366, 75154, 75154, 88712,    20,   181,   366,\n",
       "          15922,   617, 14725,   216,  1431,  5177,   879,  1485,  1120,   136,\n",
       "           8178,  4899,   390, 31077,  1094,   789,   820,  1310,   626,  3766,\n",
       "           1890,    13, 75154, 75154,     1,  1333,   916,  3470,  1055,    31,\n",
       "            425,  5566,  1581,   789,   439,   879,     6,   269,  1615,   411,\n",
       "            677, 75154, 75154,    14,     8,    28,   776,   188,   105,    42,\n",
       "             16,    57,  8743, 12017,  2012,  1095,  2817,    30,   154,  2349,\n",
       "           2797,   682,    23,  2065,     7,   307,     1,   287,   822,  6554,\n",
       "             27,  2356,  2602,   993,  6789,    26,  5339, 42947,  1483,  2926,\n",
       "          16284,    66,  2617,    61,  1958,  8012,  1370,  4492,   960,    24,\n",
       "           7894,  4371,   533,   150,  2083,  1856,    28,  9582,   287,   585,\n",
       "            707,  2726, 75154, 75154,  2505,   556,    27,   961,   540,   292,\n",
       "           3224,   785,    76,  2913,  1689,  3476,   128,  1394,   917,  2738,\n",
       "           1081,   215,  2096,  6602, 14755,   707,  1551, 15780,   549,   415,\n",
       "          75154, 75154,     1,  1171,  1128,  2221,  8407,    20,   374, 34337,\n",
       "             10,   311,    28,  3931,   581,   683,  2430,   606,   106,  1306,\n",
       "           1002,   431,    28,  2655,   220,   374,   407,   556,    10,  6713,\n",
       "              8,    14,  1847,    35,    11,  1252,   710,   374,   619, 16847,\n",
       "             14,     8,   270,    49,  1373,   985,  3533,    36,   116,    73,\n",
       "            426,   710,   374,    82,    14,  1887, 10924,  3102,  5743,  4800,\n",
       "           1507,  1507,  2087,     2,  1394,   390,  1116,   689,    43,   669,\n",
       "          75154, 75154,   648,  8314,    19,   700,  5852,   106,    50,    50,\n",
       "              4,   390,  3055,    68,    67,  2505,   321,  8551,  4167,   480,\n",
       "            481,   522,  8928,   774,  3604,  2081,   311, 26469,  1967,  1792,\n",
       "           1031,    31,   490, 32368,  3275,  2087,    14, 75154, 75154, 75154,\n",
       "          75154],\n",
       "         [ 2229,     1, 22214,  5627,  3508, 12294, 21360,   959,   569,  2142,\n",
       "           1946,  1626, 16209, 75154, 75154,     1,  1313,   173,  1896,  8213,\n",
       "           3336,  1399, 83738,   390,  9485,    36,  1356,   721, 57628,    76,\n",
       "          34182,  6085,  4029,   899,   113,   291,  1101,  5001,   267,  6206,\n",
       "           2657,  1399,   236,   120,  7949,  4139,  8441,  2498,   173,  1246,\n",
       "          11499,  4409, 32951,  8643, 29102,   404,     1,   857, 27598,  3767,\n",
       "            571,   106,   471,  4905,  4952,   822, 21101, 75154, 75154,   117,\n",
       "             29,     1,   347,    17,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0]]),\n",
       " tensor([138, 331,  74]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用Pytorch的RandomSampler來進行indice讀取並建立dataloader\n",
    "reviews_dataset = dataset(review_pairs, vocab)\n",
    "custom_dataloader = DataLoader(reviews_dataset,\n",
    "                                      batch_size = 3,\n",
    "                                      sampler = RandomSampler(review_pairs),\n",
    "                                      collate_fn = collate_fn\n",
    ")\n",
    "\n",
    "next(iter(custom_dataloader))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_nlp",
   "language": "python",
   "name": "pytorch_nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
