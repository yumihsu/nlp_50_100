{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的: 更加熟習pytorch的tensor操作\n",
    "\n",
    "pytorch中有提供很多的API，讓使用者針對tensor進行各式各樣的操作，本次的作業希望讀者由pytorch的[官方網站](https://pytorch.org/docs/stable/torch.html)中選定四個針對tensor操作的API，對他的使用方法進行範例操作演練。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 選定的API 函數\n",
    "\n",
    "**請寫下選定的API functions**\n",
    "\n",
    "ex:\n",
    "* torch.from_array() / tensor.numpy()\n",
    "* torch.unsqueeze() / torch.squeeze()\n",
    "* tensor.transpose() / tensor.permute()\n",
    "* torch.reshape() / tensor.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import torch and other required modules\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 範例:\n",
    "### Function 1 - torch.from_array() / tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: <class 'numpy.ndarray'>, float64\n",
      "b: <class 'torch.Tensor'>, torch.float64\n",
      "c: <class 'torch.Tensor'>, torch.float64\n",
      "d: <class 'numpy.ndarray'>, float64\n"
     ]
    }
   ],
   "source": [
    "# Example 1 - 將torch tensor與numpy ndarray互相轉換\n",
    "a = np.random.rand(1,2,3,3)\n",
    "print(f'a: {type(a)}, {a.dtype}')\n",
    "b = torch.from_numpy(a)\n",
    "print(f'b: {type(b)}, {b.dtype}')\n",
    "c = torch.tensor(a)\n",
    "print(f'c: {type(c)}, {c.dtype}')\n",
    "d = c.numpy()\n",
    "print(f'd: {type(d)}, {d.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: <class 'numpy.ndarray'>, int64\n",
      "b: <class 'torch.Tensor'>, torch.int64\n",
      "c: <class 'torch.Tensor'>, torch.int64\n",
      "d: <class 'numpy.ndarray'>, int64\n"
     ]
    }
   ],
   "source": [
    "# Example 2 - 經過轉換後，torch tensor與numpy array依然有相近的資料型態\n",
    "a = np.random.randint(low=0, high=10, size=(2,2))\n",
    "print(f'a: {type(a)}, {a.dtype}')\n",
    "b = torch.from_numpy(a)\n",
    "print(f'b: {type(b)}, {b.dtype}')\n",
    "c = torch.tensor(a)\n",
    "print(f'c: {type(c)}, {c.dtype}')\n",
    "d = c.numpy()\n",
    "print(f'd: {type(d)}, {d.dtype}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 1 - torch.linespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 10.,  20.,  30.,  40.,  50.,  60.,  70.,  80.,  90., 100.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - 可對選定範內的數字進行切分，相當於N分位數\n",
    "torch.linspace(10, 100, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  10.0000,   -2.2222,  -14.4444,  -26.6667,  -38.8889,  -51.1111,\n",
       "         -63.3333,  -75.5556,  -87.7778, -100.0000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2 - 可以選定倒退 ex end=負數\n",
    "torch.linspace(10, end=-100, steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 2 - torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - give the shape and return the full one tensor\n",
    "torch.ones(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "torch.ones(2,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 3 - torch.as_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 4.], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - transport numpy to tensor, it can set the dtype and device locate\n",
    "a = np.array([1,2,4])\n",
    "torch.as_tensor(a, dtype=torch.float16, device = 'cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 4 - torch.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1 - flatten tensor to the 1d tensor\n",
    "a = torch.ones(2,4,3)\n",
    "torch.flatten(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
