{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearBNAC(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bias=True, dropout=0.3, is_output=False):\n",
    "        super(LinearBNAC, self).__init__()\n",
    "        if is_output and out_channels==1:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(in_channels, out_channels, bias=bias),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        elif is_output:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(in_channels, out_channels, bias=bias),\n",
    "                nn.Softmax(dim=1)\n",
    "            )   \n",
    "        else:\n",
    "            self.linear = nn.Sequential(\n",
    "                nn.Linear(in_channels, out_channels, bias=bias),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(out_channels),\n",
    "                nn.LeakyReLU(inplace=True)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        out=self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_dimention, output_classes=1):\n",
    "        super(Model, self).__init__()\n",
    "        self.layer1 = LinearBNAC(input_dimention, 128)\n",
    "        self.layer2 = LinearBNAC(128, 32)\n",
    "        self.layer3 = LinearBNAC(32,32)\n",
    "        self.output = LinearBNAC(32, output_classes, is_output=True)\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.output(x)\n",
    "        return x \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備輸入資料、優化器、標籤資料、模型輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_dimention=256,output_classes=10)\n",
    "optimizer = optim.Adam(params=model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "input_features = 256\n",
    "dummy_input = torch.randn(batch_size, input_features,)\n",
    "target = torch.tensor([9, 5, 4, 4], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0998, 0.1164, 0.0983, 0.1148, 0.0971, 0.1342, 0.0487, 0.0877, 0.0582,\n",
      "         0.1447],\n",
      "        [0.1446, 0.0715, 0.0801, 0.1736, 0.0396, 0.0784, 0.1596, 0.0632, 0.0784,\n",
      "         0.1112],\n",
      "        [0.1191, 0.0720, 0.1310, 0.1154, 0.1131, 0.0781, 0.1157, 0.1057, 0.0584,\n",
      "         0.0915],\n",
      "        [0.0972, 0.0997, 0.1022, 0.1650, 0.1136, 0.0534, 0.0912, 0.1472, 0.0924,\n",
      "         0.0383]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = model(dummy_input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 計算 CrossEntropy Loss\n",
    "* 請注意哪一個 Loss最適合：我們已經使用 softmax\n",
    "* 因為我們有使用dropout，並隨機產生dummy_input，所以各為學員得到的值會與解答不同，然而步驟原理需要相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import NLLLoss, LogSoftmax, CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(torch.log(output), target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完成back propagation並更新梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : Parameter containing:\n",
      "tensor([[ 0.0192,  0.0475, -0.0610,  ..., -0.0491,  0.0160, -0.0268],\n",
      "        [-0.0472,  0.0356,  0.0136,  ...,  0.0271, -0.0391, -0.0019],\n",
      "        [-0.0185,  0.0291,  0.0050,  ..., -0.0454,  0.0508, -0.0152],\n",
      "        ...,\n",
      "        [-0.0562, -0.0616,  0.0290,  ..., -0.0068, -0.0337,  0.0215],\n",
      "        [ 0.0500,  0.0233,  0.0470,  ...,  0.0025, -0.0418,  0.0300],\n",
      "        [-0.0151, -0.0027, -0.0221,  ...,  0.0040, -0.0377,  0.0336]],\n",
      "       requires_grad=True)\n",
      "\n",
      "\n",
      "grad : tensor([[-2.4493e-06, -6.0981e-07, -2.0408e-06,  ...,  2.9309e-06,\n",
      "          4.0316e-07, -1.7356e-06],\n",
      "        [-1.5596e-02,  3.2472e-02, -1.1739e-02,  ...,  8.6038e-03,\n",
      "          1.1438e-02,  1.1598e-02],\n",
      "        [ 3.0376e-03,  2.6958e-02, -1.3049e-02,  ..., -7.4004e-03,\n",
      "         -2.2918e-02, -6.2787e-03],\n",
      "        ...,\n",
      "        [-1.8330e-06, -2.7785e-05,  1.9422e-05,  ..., -2.8468e-06,\n",
      "          1.6728e-05,  1.0989e-05],\n",
      "        [ 4.3595e-03, -1.3811e-01,  8.8220e-02,  ..., -1.8158e-02,\n",
      "          5.9617e-02,  3.6062e-02],\n",
      "        [ 2.2357e-03, -5.0669e-03,  1.6383e-03,  ..., -1.9513e-03,\n",
      "         -3.3877e-03, -2.3392e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
    "print('\\n')\n",
    "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : Parameter containing:\n",
      "tensor([[ 0.0202,  0.0485, -0.0600,  ..., -0.0501,  0.0150, -0.0258],\n",
      "        [-0.0462,  0.0346,  0.0146,  ...,  0.0261, -0.0401, -0.0029],\n",
      "        [-0.0195,  0.0281,  0.0060,  ..., -0.0444,  0.0518, -0.0142],\n",
      "        ...,\n",
      "        [-0.0552, -0.0606,  0.0280,  ..., -0.0058, -0.0347,  0.0205],\n",
      "        [ 0.0490,  0.0243,  0.0460,  ...,  0.0035, -0.0428,  0.0290],\n",
      "        [-0.0161, -0.0017, -0.0231,  ...,  0.0050, -0.0367,  0.0346]],\n",
      "       requires_grad=True)\n",
      "\n",
      "\n",
      "grad : tensor([[-2.4493e-06, -6.0981e-07, -2.0408e-06,  ...,  2.9309e-06,\n",
      "          4.0316e-07, -1.7356e-06],\n",
      "        [-1.5596e-02,  3.2472e-02, -1.1739e-02,  ...,  8.6038e-03,\n",
      "          1.1438e-02,  1.1598e-02],\n",
      "        [ 3.0376e-03,  2.6958e-02, -1.3049e-02,  ..., -7.4004e-03,\n",
      "         -2.2918e-02, -6.2787e-03],\n",
      "        ...,\n",
      "        [-1.8330e-06, -2.7785e-05,  1.9422e-05,  ..., -2.8468e-06,\n",
      "          1.6728e-05,  1.0989e-05],\n",
      "        [ 4.3595e-03, -1.3811e-01,  8.8220e-02,  ..., -1.8158e-02,\n",
      "          5.9617e-02,  3.6062e-02],\n",
      "        [ 2.2357e-03, -5.0669e-03,  1.6383e-03,  ..., -1.9513e-03,\n",
      "         -3.3877e-03, -2.3392e-03]])\n"
     ]
    }
   ],
   "source": [
    "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
    "print('\\n')\n",
    "print('grad : {}'.format(model.layer1.linear[0].weight.grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 清空 gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight : Parameter containing:\n",
      "tensor([[ 0.0202,  0.0485, -0.0600,  ..., -0.0501,  0.0150, -0.0258],\n",
      "        [-0.0462,  0.0346,  0.0146,  ...,  0.0261, -0.0401, -0.0029],\n",
      "        [-0.0195,  0.0281,  0.0060,  ..., -0.0444,  0.0518, -0.0142],\n",
      "        ...,\n",
      "        [-0.0552, -0.0606,  0.0280,  ..., -0.0058, -0.0347,  0.0205],\n",
      "        [ 0.0490,  0.0243,  0.0460,  ...,  0.0035, -0.0428,  0.0290],\n",
      "        [-0.0161, -0.0017, -0.0231,  ...,  0.0050, -0.0367,  0.0346]],\n",
      "       requires_grad=True)\n",
      "\n",
      "\n",
      "grad : tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print('weight : {}'.format(model.layer1.linear[0].weight))\n",
    "print('\\n')\n",
    "print('grad : {}'.format(model.layer1.linear[0].weight.grad))\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('pytorch_nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "26ce5c61601092ae2803f7f2dacb793d4bc91692b256a99b8317fa1e35208634"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
